{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uhhF9Kl3KppJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wisqOKXCKt1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6413f56d-8613-486c-99fb-6278cb1ca702"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij4ZXJVNKutN",
        "outputId": "2f80df10-d2fd-4d91-b64e-91c9b3d610e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyheif\n",
            "  Downloading pyheif-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyheif) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.0->pyheif) (2.22)\n",
            "Installing collected packages: pyheif\n",
            "Successfully installed pyheif-0.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyheif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEZU_UtsSSCC"
      },
      "outputs": [],
      "source": [
        "# Define your dataset directory\n",
        "Agriculture_crop = '/content/drive/MyDrive/dataset'\n",
        "\n",
        "# Define types\n",
        "types = [\n",
        "    \"1\", \"2\", \"3\", \"4\", \"5\"\n",
        "]\n",
        "\n",
        "# Initialize lists to hold images and their labels\n",
        "CrownPreparationimages = []\n",
        "CrownPreparationlabels = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "target_size = (224, 224)  # Desired size to resize images\n",
        "\n",
        "for i, PreparationType in enumerate(types, start=1):\n",
        "    CrownPreparationFolder = os.path.join(Agriculture_crop, str(i))\n",
        "    for root, dirs, files in os.walk(CrownPreparationFolder):\n",
        "        for file_name in files:\n",
        "            img_path = os.path.join(root, file_name)\n",
        "            _, file_extension = os.path.splitext(img_path)\n",
        "            if file_extension.lower() == '.jpeg' or file_extension.lower() == '.jpg':\n",
        "            #for add photo output folder\n",
        "            #if file_extension.lower() == '.jpg':\n",
        "                img = Image.open(img_path)\n",
        "            elif file_extension.lower() == '.heic':\n",
        "\n",
        "                try:\n",
        "                    heif_file = pyheif.read(img_path)\n",
        "                    img = Image.frombytes(\n",
        "                        heif_file.mode,\n",
        "                        heif_file.size,\n",
        "                        heif_file.data,\n",
        "                        \"raw\",\n",
        "                        heif_file.mode,\n",
        "                        heif_file.stride,\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    print(f\"Error opening {img_path}: {e}\")\n",
        "                    continue\n",
        "            else:\n",
        "                print(f\"Unsupported file format: {img_path}\")\n",
        "                continue\n",
        "\n",
        "            # Resize image to target size\n",
        "            img = img.resize(target_size)\n",
        "\n",
        "            # Append image and label\n",
        "            CrownPreparationimages.append(np.array(img))\n",
        "            CrownPreparationlabels.append(PreparationType)\n",
        "\n",
        "CrownPreparationimages = np.array(CrownPreparationimages)\n",
        "CrownPreparationlabels = np.array(CrownPreparationlabels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Number of images loaded:\", len(CrownPreparationimages))\n",
        "print(\"Number of labels:\", len(CrownPreparationlabels))\n"
      ],
      "metadata": {
        "id": "j3j-j0YgXI9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66fcad3e-929f-401c-bbb5-2396c2bb3e50"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images loaded: 828\n",
            "Number of labels: 828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CRAazcDK6CS",
        "outputId": "537ef7c1-7691-498f-88a2-437cd75ef301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "21/21 [==============================] - 204s 10s/step - loss: 82.2844 - accuracy: 0.2130 - val_loss: 1.6088 - val_accuracy: 0.1928\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 210s 10s/step - loss: 1.6086 - accuracy: 0.1888 - val_loss: 1.6093 - val_accuracy: 0.2229\n",
            "Epoch 3/100\n",
            "15/21 [====================>.........] - ETA: 50s - loss: 1.6075 - accuracy: 0.2083"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.svm import SVC\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense\n",
        "\n",
        "\n",
        "# Split the dataset into training and testing\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    CrownPreparationimages, CrownPreparationlabels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "label_binarizer = LabelBinarizer()\n",
        "train_labels = label_binarizer.fit_transform(train_labels)\n",
        "test_labels = label_binarizer.transform(test_labels)\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same', activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(label_binarizer.classes_), activation=\"softmax\"))\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(train_images, train_labels, epochs=100,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMAGE SIZE = 128,128\n",
        "#--------- DATASET = 201\n",
        "#1 32,64,128 -> 29\n",
        "#2 32,32,64,64 WITH DROPOT(0.25)-> 24\n",
        "#3 64,64,128,512 -> 31.70\n",
        "\n",
        "#--------- DATASET = 804\n",
        "#4 64,64,128,512 WITH DROPOT(0.25)-> 19\n",
        "#5 64,64,128,128 WITH DROPOT(0.25)-> 16\n",
        "\n",
        "# IMAGE SIZE = 224,224\n",
        "#--------- DATASET = 804\n",
        "#6 64,64,128,128 WITH DROPOT(0.25)-> 16\n",
        "#7 32,64,128 -> 16\n",
        "#new code\n",
        "#8 32,32,64,64 WITH DROPOT(0.25)-> 42.85\n",
        "#9 32,32,64,64,128,128 WITH DROPOT(0.25)->19.75"
      ],
      "metadata": {
        "id": "N3Rpg9a-31w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Assuming 'model' is your trained Keras model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "P8h5T5IJh_sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Define your preprocessing function\n",
        "def preprocess_image(image_path, target_size=(128, 128)):\n",
        "    # Load image and resize\n",
        "    img = load_img(image_path, target_size=target_size)\n",
        "    # Convert image to array and normalize pixel values\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    return img_array\n",
        "\n",
        "# Load TensorFlow Lite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"/content/drive/MyDrive/model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Load test images (assuming you have a list of file paths)\n",
        "test_image_paths = [\n",
        "    '/content/drive/MyDrive/five_views/2/IMAGE 1445-11-06 02:09:24.jpg',\n",
        "    '/content/drive/MyDrive/five_views/2/IMAGE 1445-11-06 02:09:28.jpg',\n",
        "    '/content/drive/MyDrive/five_views/2/IMAGE 1445-11-06 02:09:31.jpg',\n",
        "    '/content/drive/MyDrive/five_views/2/IMAGE 1445-11-06 02:09:34.jpg',\n",
        "    '/content/drive/MyDrive/five_views/2/IMAGE 1445-11-06 02:09:37.jpg'\n",
        "]\n",
        "types = [\n",
        "    \"Finish line position\", \"Finish line continuity\", \"Finish line irregularity\", \"taper\",\n",
        "    \"line angle roundness\", \"axial wall undercut\", \"amount of occlusal reduction\",\n",
        "    \"Over reduction\", \"Ideal\"\n",
        "]\n",
        "\n",
        "# Preprocess test images\n",
        "test_images = [preprocess_image(image_path) for image_path in test_image_paths]\n",
        "test_images = np.array(test_images)\n",
        "\n",
        "# Number of top labels to retrieve for each image\n",
        "N = 3  # Adjust as needed\n",
        "\n",
        "# Prepare input and output tensors\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Run inference for each test image\n",
        "predicted_labels_all = []\n",
        "\n",
        "for image in test_images:\n",
        "    # Set input tensor\n",
        "    interpreter.set_tensor(input_details[0]['index'], np.expand_dims(image, axis=0))\n",
        "\n",
        "    # Run inference\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get output tensor\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "    # Sort predictions by probability and get top N labels\n",
        "    top_n_indices = np.argsort(output_data[0])[::-1][:N]  # Adjust N as needed\n",
        "    top_n_labels = [(index, output_data[0][index]) for index in top_n_indices]\n",
        "\n",
        "    # Append top N labels to the list\n",
        "    predicted_labels_all.extend(top_n_indices)\n",
        "\n",
        "# Count the occurrences of each label\n",
        "label_counts = Counter(predicted_labels_all)\n",
        "\n",
        "# Filter labels that appeared at least in two images\n",
        "final_labels = [label for label, count in label_counts.items() if count >= 2 and types[label] != \"Ideal\"]\n",
        "\n",
        "# Print the final predicted labels\n",
        "print(\"Final Predicted Labels:\")\n",
        "for label in final_labels:\n",
        "    if label < len(types):\n",
        "        print(f\"- {types[label]}\")\n",
        "        if types[label] == \"Finish line position\":\n",
        "            print(\"Ensure that the finish line is not more than 1.5mm above the gumline and no more than 1.5mm below the gumline.\")\n",
        "        elif types[label] == \"taper\":\n",
        "            print(\"Be sure the taper is not more than 12mm.\")\n",
        "        elif types[label] == \"amount of occlusal reduction\":\n",
        "            print(\"Ensure that the occlusal reduction is not less than 3mm.\")\n",
        "        else:\n",
        "            print(\"You have to re-curve the tooth again\")\n",
        "    else:\n",
        "        print(\"Excellent work\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO71HV9_IyEq",
        "outputId": "56c98fbe-8d11-417c-9afd-4cec95f24b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Predicted Labels:\n",
            "- amount of occlusal reduction\n",
            "Ensure that the occlusal reduction is not less than 3mm.\n",
            "- Finish line irregularity\n",
            "You have to re-curve the tooth again\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jNAuYKkdu-Y"
      },
      "outputs": [],
      "source": [
        "# add one more layer\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(512, (3, 3), activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Flatten(),\n",
        "\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(len(label_binarizer.classes_), activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpRJFSc5VHVD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "# Predict the classes of the test images\n",
        "test_predictions = model.predict(test_images)\n",
        "test_predictions_classes = np.argmax(test_predictions, axis=1)\n",
        "test_true_classes = np.argmax(test_labels, axis=1)  # Convert one-hot encoded test labels back to class indices for comparison\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(test_true_classes, test_predictions_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIW5SUxxfAwl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "ea961701-01a9-4170-9967-6ec44463db6a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-69832d62f734>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Blues\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'True labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cm' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}